//Steps

1. Zookeeper
2. Cluster: broker
3. Topics
4. Producer 
5. Consumer

//Commands

wget https://archive.apache.org/dist/kafka/3.6.0/kafka_2.12-3.6.0.tgz



tar -xvf kafka_2.12-3.6.0.tgz

mkdir -p /tmp/zookeeper1
mkdir -p /tmp/zookeeper2
mkdir -p /tmp/zookeeper3
chmod -R 777 /tmp/zookeeper1
chmod -R 777  /tmp/zookeeper2
chmod -R 777 /tmp/zookeeper3

cd /home/centos/kafka_2.12-3.6.0/config/

vi zookeeper1.properties

dataDir=/tmp/zookeeper1
clientPort=2181
admin.enableServer=true
admin.serverPort=8080
tickTime=2000
initLimit=5
syncLimit=2
server.1=localhost:2888:3888:
server.2=localhost:2989:3088
server.3=localhost:3089:3188
autopurge.snapRetainCount=3
autopurge.purgeInterval=24
------------------

to save linux file , press ESc button then shift+colon >>wq
-------------------------------------------------


cp zookeeper1.properties zookeeper2.properties
cp zookeeper1.properties zookeeper3.properties
---------------------------

vi zookeeper2.properties
dataDir=/tmp/zookeeper2
clientPort=2182
admin.enableServer=false
#admin.serverPort=8080
-----------------
vi zookeeper3.properties
dataDir=/tmp/zookeeper3
clientPort=2183
#admin.enableServer=true
#admin.serverPort=8080
------------------------------
echo "1" >> /tmp/zookeeper1/myid

-------------------
echo "2" >> /tmp/zookeeper2/myid

echo "3" >> /tmp/zookeeper3/myid
------------

--------------------

cd /home/centos/kafka_2.12-3.6.0/bin

Let's start the zookeeper:

nohup ./zookeeper-server-start.sh ../config/zookeeper1.properties &

nohup ./zookeeper-server-start.sh ../config/zookeeper2.properties &

nohup ./zookeeper-server-start.sh ../config/zookeeper3.properties &

echo srvr |nc localhost 2181 | grep Mode
echo srvr |nc localhost 2182 | grep Mode
echo srvr |nc localhost 2183 | grep Mode
----------------------
Let's create Kafka cluster

mkdir -p /tmp/kafka1
mkdir -p /tmp/kafka2
mkdir -p /tmp/kafka3
mkdir -p /tmp/kafka4

chmod -R 777 /tmp/kafka1
chmod -R 777 /tmp/kafka2
chmod -R 777 /tmp/kafka3
chmod -R 777 /tmp/kafka4

cd /home/centos/kafka_2.12-3.6.0/config

vi server1.properties
broker.id=10
listeners=PLAINTEXT://192.168.255.128:9092
log.dirs=/tmp/kafka1
num.partitions=4
min.insync.replicas=2
default.replication.factor=3
offsets.topic.replication.factor=2 
transaction.state.log.replication.factor=2
transaction.state.log.min.isr=2
log.flush.interval.messages=10000
log.flush.interval.ms=1000
log.retention.hours=168
log.segment.bytes=1073741824
zookeeper.connect=localhost:2181,localhost:2182,localhost:2183
group.initial.rebalance.delay.ms=5000
auto.leader.rebalance.enable=true
compression.type=lz4
delete.topic.enable=true
message.max.bytes=1048588
broker.rack=RC1
num.network.threads=3
num.io.threads=8
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
---------------------
cp server1.properties server2.properties
cp server2.properties server3.properties
cp server3.properties server4.properties

------------------------
vi server2.properties	
broker.id=20
listeners=PLAINTEXT://192.168.255.128:9093
log.dirs=/tmp/kafka2
broker.rack=RC1
--------------------------------------------
vi server3.properties
broker.id=30
listeners=PLAINTEXT://192.168.255.128:9094
log.dirs=/tmp/kafka3
broker.rack=RC2
---------------------------------
vi server4.properties
broker.id=40
listeners=PLAINTEXT://192.168.255.128:9095
log.dirs=/tmp/kafka4
broker.rack=RC2
----------------------------
To run Kakfa brroker

cd /home/centos/kafka_2.12-3.6.0/bin

nohup ./kafka-server-start.sh ../config/server1.properties &

nohup ./kafka-server-start.sh ../config/server2.properties &


nohup ./kafka-server-start.sh ../config/server3.properties &

nohup ./kafka-server-start.sh ../config/server4.properties &

ps -ef|grep kafka

./zookeeper-shell.sh localhost:2181 ls /brokers/ids
./zookeeper-shell.sh localhost:2181 get /controller
------------------------------------------

To list the topics 
 ./kafka-topics.sh --list --bootstrap-server 192.168.255.128:9092
 
 to create a topic demo1
 ./kafka-topics.sh --create --topic demo1 --bootstrap-server 192.168.255.128:9092

 ./kafka-topics.sh --describe --topic demo2 --bootstrap-server 192.168.255.128:9092
 
 
 ./kafka-topics.sh --create --topic demo2 --partitions 2 --replication-factor 2 --bootstrap-server 192.168.255.128:9092 --config min.insync.replicas=1
 

  ./kafka-topics.sh --describe --topic demo2 --bootstrap-server 192.168.255.128:9092

./kafka-configs.sh --entity-type topics --entity-name demo2 --alter --add-config min.insync.replicas=2 --bootstrap-server 192.168.255.128:9092	

./kafka-topics.sh --create --topic demo3 --replica-assignment 40:10,30:20,20:30 --bootstrap-server 192.168.255.128:9092

./kafka-topics.sh --describe --topic demo3 --bootstrap-server 192.168.255.128:9092

to write the messages using commandprompt
./kafka-console-producer.sh --topic demo3  --bootstrap-server 192.168.255.128:9092

to read the messages using command prompt


./kafka-console-consumer.sh --topic demo3 --bootstrap-server 192.168.255.128:9092 --from-beginning


./kafka-console-consumer.sh --topic demo3 --bootstrap-server 192.168.255.128:9092 --partition 0 --offset 0


./kafka-console-producer.sh --bootstrap-server 192.168.255.128:9092 --topic demo2 --property parse.key=true --property key.separator=,

./kafka-console-consumer.sh --topic demo2 --from-beginning --bootstrap-server 192.168.255.128:9092


./kafka-console-consumer.sh --topic demo2 --partition 0 --offset 0 --bootstrap-server 192.168.255.128:9092

./kafka-console-consumer.sh --topic demo2 --partition 1 --offset 0 --bootstrap-server 192.168.255.128:9092..


./kafka-console-consumer.sh --topic demo2 --partition 1 --offset 0 --bootstrap-server 192.168.255.128:9092 --property print.key=true --property print.timestamp=true
